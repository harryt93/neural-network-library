{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neural Network Library Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Released: 08/05/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This documentation describes how to use the Neural Network Library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the Neural Network Library, use the import statements below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train function accepts datasets. It requires a train_set to train, and also accepts a validation_set for evaluation. The score function accepts a test_set. These different sets are consistent with the usual machine learning methodologies involving training, testing, and validation. \n",
    "\n",
    "Each of the train_set, test_set, and validation_set are examples of a dataset. In this documentation, dataset has a specific meaning, it's a list containing two arrays. The first array is an array of feature vectors, the second item is an arary of label vectors. Each feature vector and label vector must be an array in it's own right, even if it has only one entry. \n",
    "\n",
    "The following summary should help explain how to put together an appropriate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_set is a list of two arrays.\n",
    "train_set = [x, y]\n",
    "\n",
    "# x is a numpy array where each element is itself an array of features.\n",
    "x.shape = (16, 4)\n",
    "x = array([[ 0.25,  0.5 ,  0.75,  0.3 ],\n",
    "           [ 0.75,  0.25,  0.6 ,  0.5 ],\n",
    "           [ 0.25,  0.8 ,  0.2 ,  0.25],\n",
    "           [ 0.7 ,  0.75,  0.1 ,  0.4 ],\n",
    "           [ 0.2 ,  0.5 ,  0.75,  0.25],\n",
    "           [ 0.5 ,  0.8 ,  0.75,  0.25],\n",
    "           [ 0.25,  0.75,  0.5 ,  0.5 ],\n",
    "           [ 0.1 ,  0.5 ,  0.75,  0.9 ],\n",
    "           [ 0.7 ,  0.75,  0.4 ,  0.5 ],\n",
    "           [ 0.25,  0.5 ,  0.75,  0.2 ],\n",
    "           [ 0.1 ,  0.75,  0.7 ,  0.8 ],\n",
    "           [ 0.5 ,  0.4 ,  0.75,  0.25],\n",
    "           [ 0.75,  0.5 ,  0.5 ,  0.9 ],\n",
    "           [ 0.6 ,  0.75,  0.6 ,  0.5 ],\n",
    "           [ 0.2 ,  0.7 ,  0.25,  0.75],\n",
    "           [ 0.25,  0.3 ,  0.75,  0.5 ]])\n",
    "      \n",
    "# y is a numpy array where each element is itself an array of labels, in this case, there is only one label.\n",
    "y.shape = (16, 1)\n",
    "y = array([[ 0.6125],\n",
    "           [ 1.0475],\n",
    "           [ 0.5325],\n",
    "           [ 0.915 ],\n",
    "           [ 0.5525],\n",
    "           [ 0.95  ],\n",
    "           [ 0.7375],\n",
    "           [ 1.01  ],\n",
    "           [ 1.105 ],\n",
    "           [ 0.5375],\n",
    "           [ 1.015 ],\n",
    "           [ 0.7125],\n",
    "           [ 1.3125],\n",
    "           [ 1.095 ],\n",
    "           [ 0.6025],\n",
    "           [ 0.6625]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### toy_data_wiggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a toy dataset for a basic wiggly line. There are only 16 datapoints in the training set and 4 points in the test set. There is no validation set. Each feature vector contains 4 features, each label vector contains 1 label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.toy_data_wiggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = nn.toy_data_wiggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### toy_data_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a toy dataset for MNIST. There are 50,000 datapoints in the train_set, 10,000 datapoints in the valid_set, and 10,000 datapoints in the test_set. Each feature vector contains 784 features, each of the pixels of the image. Each label vector contains 10 labels, a one hot encoded vector of the numeral represented by the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.toy_data_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = nn.toy_data_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function initialises the neural network object, it requires a vector of layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__init__(layers=[784, 30, 10], \n",
    "        cost_function=\"quadratic\", \n",
    "        activation_function=\"sigmoid\", \n",
    "        regularisation_coefficient=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_network = nn.network(layers=[784, 30, 10], \n",
    "                        cost_function=\"quadratic\", \n",
    "                        activation_function=\"sigmoid\", \n",
    "                        regularisation_coefficient=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Parameters</u><br><br>\n",
    "<b>layers : </b> list, required\n",
    "<br><br>A list of layer sizes, including input and output layers.\n",
    "<br>Example: [784, 30, 10]\n",
    "\n",
    "<br>\n",
    "<b>cost_function : </b> string, optional (default=\"quadratic\"), values=(quadratic, cross-entropy)\n",
    "<br><br>The specified cost function for training, and evaluation. \n",
    "<br>Use cross-entropy with sigmoid neurons.\n",
    "\n",
    "<br>\n",
    "<b>activation_function : </b> string, optional (default=\"sigmoid\"), values=(sigmoid, relu, tanh, arctan)\n",
    "<br><br>The specified activation function for the non-linearity.\n",
    "\n",
    "<br>\n",
    "<b>regularisation_coefficient : </b> float, optional (default=\"0.0\")\n",
    "<br><br>The lambda coefficient for l2 regularisation. If left at 0, no regularisation is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains the network for a number of epochs, state is maintained between calls, so running the function twice in a row will train for double the number of epochs. The usual parameters are required for running a training operation, including learning rate, number of epochs, and batch size. There are options for outputting training progress including the frequency of evaluation, method of output and whether or not a validation set is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.train(train_set, epochs, learning_rate, \n",
    "         batch_size=32, progress=None, \n",
    "         evaluation_method=\"loss\", evaluation_frequency=100, \n",
    "         validation_set=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_network.train(train_set=train_set, epochs=100, learning_rate=0.1, \n",
    "                 batch_size=50, progress=None, \n",
    "                 evaluation_method=\"loss\", evaluation_frequency=1, \n",
    "                 validation_set=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<u>Parameters</u><br><br>\n",
    "<b>train_set : </b> dataset\n",
    "<br><br>The training dataset. See section on Input Data Format above for details.\n",
    "\n",
    "<br><b>epochs :</b> int, required\n",
    "<br><br>The number of epochs to train for. (Complete passes through the training data.)\n",
    "\n",
    "<br><b>learning_rate :</b> float, required\n",
    "<br>The learning rate, controls how large the weight updates are. \n",
    "<br><br>Small values may cause the network to learn very slowly. Large values may cause non-convergence.\n",
    "\n",
    "<br><b>batch_size :</b> int, optional (default=32)\n",
    "<br><br>The number of training examples to use in Stochastic Gradient Descent every time the weights are updated.\n",
    "\n",
    "<br><b>progress :</b> string, optional (default=None)\n",
    "<br><br>Takes three values, \"graph\", \"percentage_only\", or \"text\". If graph, a graph will be displayed with the training losses, if text is specified, then training loss will be printed as it goes. In both cases, if validation data is provided with the validation_set parameters, this will be printed also.\n",
    "\n",
    "<br><b>evaluation_method :</b> string, optional (default=\"loss\"), values=(loss, accuracy)\n",
    "<br><br>Determines whether results are displayed as a loss or accuracy. \n",
    "<br>If loss is chosen, the training and validation loss will be displayed, using whichever cost function provided when the model was created. If accuracy is chosen, then accuracy will be displayed.\n",
    "\n",
    "<br><b>evaluation_frequency :</b> int, optional (default=100)\n",
    "<br><br>The frequency in epochs to evaluate progress. \n",
    "<br>Example: If number of epochs is 1000, and evaluation_frequency is 100, then ten evaluations will be made, giving you ten data points on the loss graphs.\n",
    "<br>If too many evaluations are made, training will be slowed down.\n",
    "\n",
    "<br><b>validation_set :</b> dataset, optional (default=None)\n",
    "<br><br>The validation dataset. See section on Input Data Format above for details.\n",
    "<br>If this is provided, the algorithm will evaluate the model on the validation data at each evaluation (see evaluation_frequency parameter). It will automatically be plotted on the output loss graphs as a seperate line.\n",
    "\n",
    "<br><b>dropout :</b> int, optional (default=None)\n",
    "<br><br>The keep probability for dropout.\n",
    "\n",
    "<br><br>\n",
    "<u>Outputs</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when calculating the training loss, the model will use only a portion of the training set. The size of this portion will be the same as the size of the validation set, otherwise it will be 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>Textual Loss Output :</b> string\n",
    "<br><br>Results are output as new lines. The result that is output depends on what parameter was provided for evaluation_method. It will either be an accuracy or a loss. If loss is provided, the cost function used will be the one specified at model creation, the output will not indicate which loss model is being used.\n",
    "<br> This output is only outputted if the progress parameter is set to \"text\".\n",
    "<br>An example is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training/Validation Accuracy: 0.954/0.8796. <br>\n",
    "Training/Validation Accuracy: 0.955/0.8799. <br>\n",
    "Training/Validation Accuracy: 0.956/0.88. <br>\n",
    "Training/Validation Accuracy: 0.959/0.8802. <br>\n",
    "Training/Validation Accuracy: 0.959/0.8799. <br>\n",
    "Training/Validation Accuracy: 0.959/0.8799. <br>\n",
    "Training/Validation Accuracy: 0.96/0.8798. <br>\n",
    "Training/Validation Accuracy: 0.96/0.8803. <br>\n",
    "Training/Validation Accuracy: 0.96/0.8809. <br>\n",
    "Training/Validation Accuracy: 0.96/0.8809.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>Graphical Loss Output :</b> bokeh graph\n",
    "<br><br>Results are output as a bokeh graph with a standard set of tools for navigation. The result that is output depends on what parameter was provided for evaluation_method. It will either be an accuracy or a loss. If loss is provided, the cost function used will be the one specified at model creation, the graph will not indicate which loss model is being used.\n",
    "<br>This output is only outputted if the progress parameter is set to \"graph\".\n",
    "<br>Whilst the network is training, progress is shown as a percentage.\n",
    "<br>An example is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](graph_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function evaluates the model once, using the provided test set, and a specified evaluation method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.evaluate(test_set, evaluation_method=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Parameters</u><br><br>\n",
    "<b>test_set : </b> dataset\n",
    "<br><br>The test dataset. See section on Input Data Format above for details.\n",
    "\n",
    "<br>\n",
    "<b>evaluation_method : </b> string, optional (default=\"loss\"), values=(loss, accuracy)\n",
    "<br><br>Specifies whether the evaluation is done using an accuracy or a loss. If loss is chosen, then the cost function used will be the one specified at model creation.\n",
    "\n",
    "<br>\n",
    "<u>Output</u><br><br>\n",
    "<b>score : </b> float\n",
    "<br><br>An accuracy score between 0 and 1.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an advanced user function that searches over a a range of values for a supplied parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.search_parameter(train_set, valid_set, \n",
    "                    search_parameter, levels, \n",
    "                    epochs, evaluation_frequency, \n",
    "                    model_parameters, train_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.search_parameter(train_set=train_set, valid_set=valid_set, \n",
    "                    search_parameter=\"regularisation_coefficient\", levels=[0.0001, 0.0002, 0.0003, 0.0004, 0.0005],\n",
    "                    epochs=100, evaluation_frequency=2,\n",
    "                    model_parameters={\"layers\":[784, 30, 10],\n",
    "                                      \"cost_function\":\"quadratic\",\n",
    "                                      \"activation_function\":\"sigmoid\",\n",
    "                                      \"regularisation_coefficient\":0.001},\n",
    "                    train_parameters={\"learning_rate\":1,\n",
    "                                      \"batch_size\":50,\n",
    "                                      \"dropout\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Parameters</u><br><br>\n",
    "<b>train_set : </b> dataset\n",
    "<br><br>The training dataset. See section on Input Data Format above for details.\n",
    "\n",
    "<br>\n",
    "<b>valid_set : </b> dataset\n",
    "<br><br>The validation dataset. See section on Input Data Format above for details. Note that this is NOT optional.\n",
    "\n",
    "<br>\n",
    "<b>search_parameter : </b> string\n",
    "<br><br>The parameter to search, must be a valid parameter.\n",
    "\n",
    "<br>\n",
    "<b>levels : </b> list\n",
    "<br><br>The different levels to search. A neural network will be created and trained for each value in the list. The types of the values will depend on which parameter is being searched.\n",
    "\n",
    "<br>\n",
    "<b>epochs : </b> int\n",
    "<br><br>The number of epochs to train for. See train function for more information.\n",
    "\n",
    "<br>\n",
    "<b>evaluation_frequency : </b> int\n",
    "<br><br>The frequency at which the model is evaluated. See train function for more information.\n",
    "\n",
    "<br>\n",
    "<b>model_parameters : </b> dictionary\n",
    "<br><br>A dictionary of all of the model parameters. Must include entries for \"layers\", \"cost_function\", \"activation_function\", and \"regularisation_coefficient\". All parameters must be provided, even the one that is being searched, this parameter will be internally overridden by the different levels.\n",
    "\n",
    "<br>\n",
    "<b>train_parameters : </b> dictionary\n",
    "<br><br>A dictionary of all of the training parameters. Must include entries for \"learning_rate\", \"batch_size\", and \"dropout\". All parameters must be provided, even the one that is being searched, this parameter will be internally overridden by the different levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>Graphical Accuracy Output :</b> bokeh graph\n",
    "<br><br>Results are output as a bokeh graph with the validation accuracies plotted for each level. \n",
    "<br>An example is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](search_parameter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function resets the weights and biases in the network. It takes no parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### show_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function prints out the current settings of the model that were specified at model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_network.show_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function draws a pretty picture of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_network.draw_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will be something like the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](draw_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
